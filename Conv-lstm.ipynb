{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this model we are using convLSTM to predict the next frame of a video based on past video sequences. We use convLSTM, which is a LSTM layer but the input transformation and gate operations are replaced by convolutional operations, that allow to capture spatio-temporal dependencies. The input video will be the downsampled version of the original video, with size 8x8 pixels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import h5py\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre process the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir=os.listdir('/home/catia/Desktop/zebrafish/data')\n",
    "dir.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "minimum=1000\n",
    "maximum=0\n",
    "selected_slice=23\n",
    "j=0\n",
    "for i in range(selected_slice,len(dir),100):\n",
    "    im=h5py.File('data/'+dir[i],'r+')\n",
    "    img=list(im['d1']) \n",
    "    #print (dir[i])\n",
    "    new_min=np.min(img)\n",
    "    new_max=np.max(img)\n",
    "    if new_min < minimum:\n",
    "        minimum=new_min\n",
    "        #print (minimum)\n",
    "    if new_max > maximum:\n",
    "        maximum=new_max\n",
    "        #print (maximum)\n",
    "    j=j+1\n",
    "    \n",
    "    \n",
    "num_img=j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=np.zeros((num_img,400,400))\n",
    "j=0\n",
    "\n",
    "# Data starts by having values between minimum and maximum\n",
    "for i in range (selected_slice,len(dir),100):\n",
    "    im=h5py.File('data/'+dir[i],'r+')\n",
    "    img=list(im['d1']) \n",
    "    img=img-minimum # So the data is between 0 and maximum\n",
    "    img=img/(0.5*(maximum-minimum)) # So the data is between 0 and 2\n",
    "    img=img/2 # So the data is between -1 and 1\n",
    "    data[j,:,:]=img # Store the image into the variable data\n",
    "    j=j+1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "down_data=np.zeros((num_img,8,8))\n",
    "for i in range(0,len(down_data)):\n",
    "    img=data[i,:,:]\n",
    "    dimg=np.zeros((8,8))\n",
    "    for j in range (0,8):\n",
    "        for k in range (0,8):\n",
    "            dimg[j,k]=np.mean(img[j*50:j*50+50,k*50:k*50+50])\n",
    "    down_data[i,:,:]=dimg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8839, 8, 8)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "down_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The network can't receive the entire training data set at once, so we have to reshape the data to (sequence,timesteps,row,col,1), `sequence` is the number of sequence examples, `timesteps` is how far into the past we are looking in each example, and `row`,`col`and `1` is the shape of the images since we only have one channel (gray scale images)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_data=down_data[0:7000,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7000, 8, 8)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "past=20 #how far into the past we are looking\n",
    "input_data=np.zeros((len(x_train_data)-past,past,x_train_data.shape[1],x_train_data.shape[2],1))\n",
    "\n",
    "for i in range(past,len(x_train_data)):\n",
    "    input_data[i-past,:,:,:,0]=x_train_data[i-past:i,:,:]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 8, 8)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_data[20-20:20,:,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6980, 20, 8, 8, 1)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 8, 8)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data[4,:,:,:,0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_data=down_data[past+1:7001]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6980, 20, 8, 8, 1)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_data=y_train_data.reshape((6980, 1, 8, 8, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6980, 1, 8, 8, 1)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional_recurrent import ConvLSTM2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "import numpy as np\n",
    "import pylab as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq = Sequential()\n",
    "seq.add(ConvLSTM2D(filters=40, kernel_size=(3, 3),\n",
    "                   input_shape=(None, 8, 8, 1),\n",
    "                   padding='same', return_sequences=True))\n",
    "seq.add(BatchNormalization())\n",
    "\n",
    "seq.add(ConvLSTM2D(filters=40, kernel_size=(3, 3),\n",
    "                   padding='same', return_sequences=True))\n",
    "seq.add(BatchNormalization())\n",
    "\n",
    "seq.add(ConvLSTM2D(filters=40, kernel_size=(3, 3),\n",
    "                   padding='same', return_sequences=True))\n",
    "seq.add(BatchNormalization())\n",
    "\n",
    "seq.add(ConvLSTM2D(filters=40, kernel_size=(3, 3),\n",
    "                   padding='same', return_sequences=True))\n",
    "seq.add(BatchNormalization())\n",
    "\n",
    "seq.add(Conv3D(filters=1, kernel_size=(3, 3, 3),\n",
    "               activation='sigmoid',\n",
    "               padding='same', data_format='channels_last'))\n",
    "seq.compile(loss='binary_crossentropy', optimizer='adadelta',metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv_lst_m2d_29 (ConvLSTM2D) (None, None, 8, 8, 40)    59200     \n",
      "_________________________________________________________________\n",
      "batch_normalization_29 (Batc (None, None, 8, 8, 40)    160       \n",
      "_________________________________________________________________\n",
      "conv_lst_m2d_30 (ConvLSTM2D) (None, None, 8, 8, 40)    115360    \n",
      "_________________________________________________________________\n",
      "batch_normalization_30 (Batc (None, None, 8, 8, 40)    160       \n",
      "_________________________________________________________________\n",
      "conv_lst_m2d_31 (ConvLSTM2D) (None, None, 8, 8, 40)    115360    \n",
      "_________________________________________________________________\n",
      "batch_normalization_31 (Batc (None, None, 8, 8, 40)    160       \n",
      "_________________________________________________________________\n",
      "conv_lst_m2d_32 (ConvLSTM2D) (None, None, 8, 8, 40)    115360    \n",
      "_________________________________________________________________\n",
      "batch_normalization_32 (Batc (None, None, 8, 8, 40)    160       \n",
      "_________________________________________________________________\n",
      "conv3d_7 (Conv3D)            (None, None, 8, 8, 1)     1081      \n",
      "=================================================================\n",
      "Total params: 407,001\n",
      "Trainable params: 406,681\n",
      "Non-trainable params: 320\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "seq.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6631 samples, validate on 349 samples\n",
      "Epoch 1/30\n",
      "6631/6631 [==============================] - 1037s 156ms/step - loss: 0.3354 - acc: 0.0000e+00 - val_loss: 0.3293 - val_acc: 0.0000e+00\n",
      "Epoch 2/30\n",
      "2500/6631 [==========>...................] - ETA: 10:31 - loss: 0.3319 - acc: 0.0000e+00"
     ]
    }
   ],
   "source": [
    "seq.fit(input_data, y_train_data, batch_size=10,\n",
    "        epochs=30, validation_split=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
